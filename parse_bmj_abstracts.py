#!/usr/bin/env python3
"""
BMJæœŸåˆŠæ‘˜è¦è§£æå·¥å…·
å°†BMJæœŸåˆŠæ‘˜è¦æ–‡æœ¬æ–‡ä»¶è§£ææˆç»“æ„åŒ–çš„è¡¨æ ¼æ•°æ®
"""

import pandas as pd
import re
from datetime import datetime
from pathlib import Path
import json

class BMJAbstractParser:
    def __init__(self):
        self.articles = []
        self.current_article = {}
        self.current_section = None
        
    def parse_bmj_abstracts(self, file_path):
        """è§£æBMJæ‘˜è¦æ–‡æœ¬æ–‡ä»¶"""
        print(f"ğŸ“„ å¼€å§‹è§£æBMJæ‘˜è¦æ–‡ä»¶: {file_path}")
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # æŒ‰æ–‡ç« åˆ†å‰²ï¼ˆæ¯ä¸ªæ–‡ç« ä»¥æ•°å­—+ç‚¹å·å¼€å§‹ï¼‰
            article_pattern = r'(\d+)\.\s*BMJ\.\s*(.+?)(?=\n\n\d+\.\s*BMJ\.|\Z)'
            articles = re.findall(article_pattern, content, re.DOTALL)
            
            print(f"ğŸ“Š æ‰¾åˆ° {len(articles)} ç¯‡æ–‡ç« ")
            
            for i, (article_num, article_content) in enumerate(articles, 1):
                print(f"ğŸ” è§£æç¬¬ {i} ç¯‡æ–‡ç« ...")
                article_data = self.parse_single_article(article_num, article_content)
                if article_data:
                    self.articles.append(article_data)
            
            print(f"âœ… æˆåŠŸè§£æ {len(self.articles)} ç¯‡æ–‡ç« ")
            return self.articles
            
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
            return []
        except Exception as e:
            print(f"âŒ è§£ææ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return []
    
    def parse_single_article(self, article_num, content):
        """è§£æå•ç¯‡æ–‡ç« """
        article = {
            'article_number': int(article_num),
            'parsed_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # æå–æœŸåˆŠä¿¡æ¯è¡Œ
        journal_pattern = r'BMJ\.\s*(\d{4})\s+(\w+)\s+(\d+);(\d+):([e\d]+)\.\s*doi:\s*([\d\.-]+/[\w\.-]+)\.'
        journal_match = re.search(journal_pattern, content)
        
        if journal_match:
            article['journal'] = 'BMJ'
            article['pub_year'] = journal_match.group(1)
            article['pub_month'] = journal_match.group(2)
            article['pub_day'] = journal_match.group(3)
            article['volume'] = journal_match.group(4)
            article['issue'] = journal_match.group(5)
            article['doi'] = journal_match.group(6)
        
        # æå–æ ‡é¢˜
        title_pattern = r'\.\s*doi:\s*[\d\.-]+/[\w\.-]+\.\s*\n\n(.+?)\n\n'
        title_match = re.search(title_pattern, content, re.DOTALL)
        if title_match:
            title = title_match.group(1).replace('\n', ' ').strip()
            # æ¸…ç†å¤šä½™çš„ç©ºæ ¼
            title = re.sub(r'\s+', ' ', title)
            article['title'] = title
        
        # æå–ä½œè€…ä¿¡æ¯
        authors_pattern = r'([A-Za-z\s\-\.]+\(\d+\)(?:,\s*[A-Za-z\s\-\.]+\(\d+\)(?:\(\d+\))*\)*)'
        authors_matches = re.findall(authors_pattern, content)
        
        if authors_matches:
            # å¤„ç†ä½œè€…åˆ—è¡¨
            authors_list = []
            for author_match in authors_matches:
                # æå–ä½œè€…å§“åå’Œæœºæ„ç¼–å·
                author_parts = re.findall(r'([A-Za-z\s\-\.]+)\((\d+)\)', author_match)
                for name, institution_num in author_parts:
                    authors_list.append({
                        'name': name.strip(),
                        'institution_num': institution_num
                    })
            
            article['authors'] = authors_list
            article['author_count'] = len(authors_list)
            
            # åˆ›å»ºä½œè€…å­—ç¬¦ä¸²
            author_names = [author['name'] for author in authors_list]
            article['authors_str'] = ', '.join(author_names)
        
        # æå–æœºæ„ä¿¡æ¯
        institution_pattern = r'\(\d+\)([A-Za-z\s,\.\-@]+?)(?=\(\d+\)|Author information:|OBJECTIVE:|CONCLUSIONS:|DOI:|Conflict|$)'
        institution_matches = re.findall(institution_pattern, content, re.DOTALL)
        
        institutions = []
        for inst in institution_matches:
            inst_clean = inst.strip()
            if inst_clean and len(inst_clean) > 10:  # è¿‡æ»¤æ‰å¤ªçŸ­çš„æœºæ„ä¿¡æ¯
                # æ¸…ç†æœºæ„ä¿¡æ¯
                inst_clean = re.sub(r'\s+', ' ', inst_clean)
                institutions.append(inst_clean)
        
        article['institutions'] = institutions
        article['institution_count'] = len(institutions)
        
        # æå–ç ”ç©¶ç›®çš„/èƒŒæ™¯
        objective_pattern = r'OBJECTIVE:\s*(.+?)(?=DESIGN:|SETTING:|PARTICIPANTS:|MAIN|RESULTS:|CONCLUSIONS:|METHODS:|Â©)'
        objective_match = re.search(objective_pattern, content, re.IGNORECASE | re.DOTALL)
        if objective_match:
            objective = objective_match.group(1).strip()
            objective = re.sub(r'\s+', ' ', objective)
            article['objective'] = objective
        
        # æå–ç ”ç©¶è®¾è®¡
        design_pattern = r'DESIGN:\s*(.+?)(?=SETTING:|PARTICIPANTS:|MAIN|RESULTS:|CONCLUSIONS:|METHODS:|Â©)'
        design_match = re.search(design_pattern, content, re.IGNORECASE | re.DOTALL)
        if design_match:
            design = design_match.group(1).strip()
            design = re.sub(r'\s+', ' ', design)
            article['design'] = design
        
        # æå–ç ”ç©¶è®¾ç½®
        setting_pattern = r'SETTING:\s*(.+?)(?=PARTICIPANTS:|MAIN|RESULTS:|CONCLUSIONS:|METHODS:|Â©)'
        setting_match = re.search(setting_pattern, content, re.IGNORECASE | re.DOTALL)
        if setting_match:
            setting = setting_match.group(1).strip()
            setting = re.sub(r'\s+', ' ', setting)
            article['setting'] = setting
        
        # æå–å‚ä¸è€…ä¿¡æ¯
        participants_pattern = r'PARTICIPANTS:\s*(.+?)(?=MAIN|RESULTS:|CONCLUSIONS:|METHODS:|Â©)'
        participants_match = re.search(participants_pattern, content, re.IGNORECASE | re.DOTALL)
        if participants_match:
            participants = participants_match.group(1).strip()
            participants = re.sub(r'\s+', ' ', participants)
            article['participants'] = participants
        
        # æå–ä¸»è¦ç»“æœæµ‹é‡
        main_outcome_pattern = r'MAIN OUTCOME MEASURES?:\s*(.+?)(?=RESULTS:|CONCLUSIONS:|METHODS:|Â©)'
        main_outcome_match = re.search(main_outcome_pattern, content, re.IGNORECASE | re.DOTALL)
        if main_outcome_match:
            main_outcome = main_outcome_match.group(1).strip()
            main_outcome = re.sub(r'\s+', ' ', main_outcome)
            article['main_outcome_measures'] = main_outcome
        
        # æå–ç»“æœ
        results_pattern = r'RESULTS:\s*(.+?)(?=CONCLUSIONS?:|CONCLUSION:|Â©)'
        results_match = re.search(results_pattern, content, re.IGNORECASE | re.DOTALL)
        if results_match:
            results = results_match.group(1).strip()
            results = re.sub(r'\s+', ' ', results)
            article['results'] = results
        
        # æå–ç»“è®º
        conclusions_pattern = r'CONCLUSIONS?:\s*(.+?)(?=Â©|Conflict|$)'
        conclusions_match = re.search(conclusions_pattern, content, re.IGNORECASE | re.DOTALL)
        if conclusions_match:
            conclusions = conclusions_match.group(1).strip()
            conclusions = re.sub(r'\s+', ' ', conclusions)
            article['conclusions'] = conclusions
        
        # æå–PMCID
        pmcid_pattern = r'PMCID:\s*(PMC\d+)'
        pmcid_match = re.search(pmcid_pattern, content)
        if pmcid_match:
            article['pmcid'] = pmcid_match.group(1)
        
        # æå–PMID
        pmid_pattern = r'PMID:\s*(\d+)\s*\[Indexed for MEDLINE\]'
        pmid_match = re.search(pmid_pattern, content)
        if pmid_match:
            article['pmid'] = pmid_match.group(1)
        
        # æå–åˆ©ç›Šå†²çªå£°æ˜
        conflict_pattern = r'Conflict of interest statement:\s*(.+?)(?=\n\n|$)'
        conflict_match = re.search(conflict_pattern, content, re.IGNORECASE | re.DOTALL)
        if conflict_match:
            conflict = conflict_match.group(1).strip()
            conflict = re.sub(r'\s+', ' ', conflict)
            article['conflict_of_interest'] = conflict
        
        return article
    
    def create_dataframe(self):
        """åˆ›å»ºDataFrameç”¨äºè¡¨æ ¼å±•ç¤º"""
        if not self.articles:
            return pd.DataFrame()
        
        # å‡†å¤‡æ•°æ®
        data = []
        for article in self.articles:
            row = {
                'æ–‡ç« ç¼–å·': article.get('article_number', ''),
                'PMID': article.get('pmid', ''),
                'PMCID': article.get('pmcid', ''),
                'DOI': article.get('doi', ''),
                'æ ‡é¢˜': article.get('title', ''),
                'ä½œè€…': article.get('authors_str', ''),
                'ä½œè€…æ•°é‡': article.get('author_count', 0),
                'å‘è¡¨å¹´ä»½': article.get('pub_year', ''),
                'å‘è¡¨æœˆä»½': article.get('pub_month', ''),
                'å·': article.get('volume', ''),
                'æœŸ': article.get('issue', ''),
                'æœŸåˆŠ': article.get('journal', 'BMJ'),
                'ç ”ç©¶ç›®çš„': article.get('objective', ''),
                'ç ”ç©¶è®¾è®¡': article.get('design', ''),
                'ç ”ç©¶è®¾ç½®': article.get('setting', ''),
                'å‚ä¸è€…': article.get('participants', ''),
                'ä¸»è¦ç»“æœæµ‹é‡': article.get('main_outcome_measures', ''),
                'ç»“æœ': article.get('results', ''),
                'ç»“è®º': article.get('conclusions', ''),
                'åˆ©ç›Šå†²çª': article.get('conflict_of_interest', ''),
                'æœºæ„æ•°é‡': article.get('institution_count', 0),
                'æœºæ„': '; '.join(article.get('institutions', []))[:500],  # é™åˆ¶é•¿åº¦
                'è§£ææ—¥æœŸ': article.get('parsed_date', '')
            }
            data.append(row)
        
        df = pd.DataFrame(data)
        return df
    
    def save_to_excel(self, df, output_file):
        """ä¿å­˜åˆ°Excelæ–‡ä»¶"""
        try:
            with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
                # ä¸»æ•°æ®è¡¨
                df.to_excel(writer, sheet_name='BMJæ–‡çŒ®', index=False)
                
                # ç»Ÿè®¡è¡¨
                stats_df = self.generate_statistics(df)
                stats_df.to_excel(writer, sheet_name='ç»Ÿè®¡ä¿¡æ¯', index=False)
                
                # è·å–å·¥ä½œè¡¨è¿›è¡Œæ ¼å¼åŒ–
                worksheet = writer.sheets['BMJæ–‡çŒ®']
                self.format_excel_worksheet(worksheet, df)
            
            print(f"ğŸ’¾ Excelæ–‡ä»¶å·²ä¿å­˜: {output_file}")
            return True
            
        except Exception as e:
            print(f"âŒ ä¿å­˜Excelæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return False
    
    def format_excel_worksheet(self, worksheet, df):
        """æ ¼å¼åŒ–Excelå·¥ä½œè¡¨"""
        try:
            from openpyxl.styles import Font, Alignment, PatternFill, Border, Side
            from openpyxl.utils import get_column_letter
            
            # æ ‡é¢˜è¡Œæ ·å¼
            header_font = Font(bold=True, color="FFFFFF", size=11)
            header_fill = PatternFill(start_color="2E86AB", end_color="2E86AB", fill_type="solid")
            header_alignment = Alignment(horizontal="center", vertical="center", wrap_text=True)
            
            # æ•°æ®è¡Œæ ·å¼
            data_font = Font(size=10)
            data_alignment = Alignment(vertical="top", wrap_text=True)
            
            # è¾¹æ¡†æ ·å¼
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            # åº”ç”¨æ ‡é¢˜è¡Œæ ·å¼
            for col_num in range(1, len(df.columns) + 1):
                cell = worksheet.cell(row=1, column=col_num)
                cell.font = header_font
                cell.fill = header_fill
                cell.alignment = header_alignment
                cell.border = thin_border
                
                # è®¾ç½®è¡Œé«˜
                worksheet.row_dimensions[1].height = 30
            
            # åº”ç”¨æ•°æ®è¡Œæ ·å¼
            for row_num in range(2, len(df) + 2):
                for col_num in range(1, len(df.columns) + 1):
                    cell = worksheet.cell(row=row_num, column=col_num)
                    cell.font = data_font
                    cell.alignment = data_alignment
                    cell.border = thin_border
                
                # è®¾ç½®æ•°æ®è¡Œé«˜
                worksheet.row_dimensions[row_num].height = 60
            
            # è®¾ç½®åˆ—å®½
            column_widths = {
                'A': 8,   # æ–‡ç« ç¼–å·
                'B': 12,  # PMID
                'C': 12,  # PMCID
                'D': 25,  # DOI
                'E': 50,  # æ ‡é¢˜
                'F': 40,  # ä½œè€…
                'G': 8,   # ä½œè€…æ•°é‡
                'H': 8,   # å‘è¡¨å¹´ä»½
                'I': 8,   # å‘è¡¨æœˆä»½
                'J': 8,   # å·
                'K': 8,   # æœŸ
                'L': 8,   # æœŸåˆŠ
                'M': 50,  # ç ”ç©¶ç›®çš„
                'N': 25,  # ç ”ç©¶è®¾è®¡
                'O': 30,  # ç ”ç©¶è®¾ç½®
                'P': 40,  # å‚ä¸è€…
                'Q': 40,  # ä¸»è¦ç»“æœæµ‹é‡
                'R': 50,  # ç»“æœ
                'S': 50,  # ç»“è®º
                'T': 30,  # åˆ©ç›Šå†²çª
                'U': 8,   # æœºæ„æ•°é‡
                'V': 50,  # æœºæ„
                'W': 15   # è§£ææ—¥æœŸ
            }
            
            # åº”ç”¨åˆ—å®½
            for col_letter, width in column_widths.items():
                if col_letter <= get_column_letter(len(df.columns)):
                    worksheet.column_dimensions[col_letter].width = width
            
            # æ·»åŠ ç­›é€‰åŠŸèƒ½
            worksheet.auto_filter.ref = worksheet.dimensions
            
            # å†»ç»“é¦–è¡Œ
            worksheet.freeze_panes = 'A2'
            
            print("âœ… Excelæ ¼å¼åŒ–å®Œæˆ")
            
        except Exception as e:
            print(f"âš ï¸  Excelæ ¼å¼åŒ–æ—¶å‡ºé”™: {e}")
    
    def generate_statistics(self, df):
        """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯"""
        stats_data = []
        
        # åŸºæœ¬ç»Ÿè®¡
        stats_data.append(['æ€»æ–‡ç« æ•°', len(df)])
        stats_data.append(['æœ‰PMIDçš„æ–‡ç« æ•°', df['PMID'].notna().sum()])
        stats_data.append(['æœ‰DOIçš„æ–‡ç« æ•°', df['DOI'].notna().sum()])
        stats_data.append(['å¹³å‡ä½œè€…æ•°é‡', df['ä½œè€…æ•°é‡'].mean()])
        stats_data.append(['æœ€å¤šä½œè€…æ•°é‡', df['ä½œè€…æ•°é‡'].max()])
        stats_data.append(['å¹³å‡æœºæ„æ•°é‡', df['æœºæ„æ•°é‡'].mean()])
        
        # æŒ‰å¹´ä»½ç»Ÿè®¡
        year_counts = df['å‘è¡¨å¹´ä»½'].value_counts().sort_index(ascending=False)
        for year, count in year_counts.head(10).items():
            stats_data.append([f'{year}å¹´å‘è¡¨æ–‡ç« æ•°', count])
        
        # æŒ‰ç ”ç©¶è®¾è®¡ç»Ÿè®¡
        design_counts = df['ç ”ç©¶è®¾è®¡'].value_counts()
        for design, count in design_counts.head(10).items():
            if pd.notna(design) and design.strip():
                stats_data.append([f'{design}', count])
        
        stats_df = pd.DataFrame(stats_data, columns=['ç»Ÿè®¡é¡¹ç›®', 'æ•°å€¼'])
        return stats_df

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“š BMJæœŸåˆŠæ‘˜è¦è§£æå·¥å…·")
    print("=" * 60)
    
    # è¾“å…¥æ–‡ä»¶è·¯å¾„
    input_file = "/Users/ziyuexu/Documents/trae_projects/paper1/abstract-BMJJournal-set (2).txt"
    
    # è¾“å‡ºæ–‡ä»¶è·¯å¾„
    output_file = "/Users/ziyuexu/Documents/trae_projects/paper1/bmj_articles_parsed.xlsx"
    
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {input_file}")
    print(f"ğŸ“Š è¾“å‡ºæ–‡ä»¶: {output_file}")
    
    # åˆ›å»ºè§£æå™¨
    parser = BMJAbstractParser()
    
    # è§£ææ–‡ä»¶
    articles = parser.parse_bmj_abstracts(input_file)
    
    if articles:
        # åˆ›å»ºDataFrame
        df = parser.create_dataframe()
        
        if not df.empty:
            print(f"\nğŸ“Š è§£æç»“æœé¢„è§ˆ:")
            print(f"æ€»æ–‡ç« æ•°: {len(df)}")
            print(f"æ•°æ®åˆ—: {', '.join(df.columns)}")
            
            # æ˜¾ç¤ºå‰3ç¯‡æ–‡ç« çš„æ‘˜è¦ä¿¡æ¯
            print(f"\nğŸ“– å‰3ç¯‡æ–‡ç« é¢„è§ˆ:")
            for i, (_, row) in enumerate(df.head(3).iterrows(), 1):
                print(f"\n{i}. {row['æ ‡é¢˜']}")
                print(f"   ä½œè€…: {row['ä½œè€…']}")
                print(f"   PMID: {row['PMID']}")
                print(f"   ç ”ç©¶è®¾è®¡: {row['ç ”ç©¶è®¾è®¡']}")
                print(f"   ç»“è®º: {str(row['ç»“è®º'])[:200]}...")
            
            # ä¿å­˜åˆ°Excel
            success = parser.save_to_excel(df, output_file)
            
            if success:
                print(f"\nğŸ‰ è§£æå®Œæˆï¼")
                print(f"ğŸ“„ Excelæ–‡ä»¶å·²ç”Ÿæˆ: {output_file}")
                print(f"ğŸ“ˆ åŒ…å« {len(df)} ç¯‡BMJæ–‡ç« çš„å®Œæ•´ä¿¡æ¯")
                print(f"ğŸ’¡ æ–‡ä»¶åŒ…å«å¤šä¸ªå·¥ä½œè¡¨ï¼šä¸»æ•°æ®è¡¨å’Œç»Ÿè®¡ä¿¡æ¯è¡¨")
            else:
                print(f"\nâŒ Excelæ–‡ä»¶ç”Ÿæˆå¤±è´¥")
        else:
            print(f"\nâŒ æœªèƒ½åˆ›å»ºæœ‰æ•ˆçš„æ•°æ®è¡¨æ ¼")
    else:
        print(f"\nâŒ æœªèƒ½è§£æåˆ°ä»»ä½•æ–‡ç« ")

if __name__ == "__main__":
    main()