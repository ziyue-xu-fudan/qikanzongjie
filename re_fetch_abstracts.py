import pandas as pd
from Bio import Entrez
import time
import concurrent.futures
import json
import os
from openai import OpenAI

# -----------------------------------------------------------------------------
# é…ç½®
# -----------------------------------------------------------------------------
Entrez.email = "your.email@example.com"  # è¯·æ›¿æ¢ä¸ºæœ‰æ•ˆé‚®ç®±

API_KEYS = [
    "sk-37c1617db0da456d8491e1094e3f6ae3",
    "sk-82a00766192049fc91da7edbca74bfd2",
    "sk-c69f18b962d54e44b14298f079bc4c66",
    "sk-d98eb5841a0b4e6c9985b72b4106c74c"
]

FILE_PATH = "/Users/ziyuexu/Documents/trae_projects/paper1/multi_journal_analysis_report.xlsx"
MODEL_NAME = "deepseek-chat"

# å®Œæ•´çš„åˆ†æ Prompt (åˆå¹¶äº† Design, Timing, Disease)
ANALYSIS_PROMPT_TEMPLATE = """
è¯·åˆ†æä»¥ä¸‹åŒ»å­¦æ–‡çŒ®æ‘˜è¦ï¼Œå¹¶æå–ä»¥ä¸‹äº”ä¸ªå…³é”®ä¿¡æ¯ã€‚
è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¿”å›ï¼Œä¸è¦åŒ…å« Markdown æ ¼å¼æ ‡è®°ï¼ˆå¦‚ ```jsonï¼‰ã€‚
å¦‚æœæ— æ³•æå–æŸä¸ªå­—æ®µï¼Œè¯·å¡«å†™ "Unknown"ã€‚

æ‘˜è¦å†…å®¹:
{abstract}

éœ€è¦æå–çš„å­—æ®µ:
1. research_design
   - Options: [Randomized Controlled Trial, Cohort Study, Case-Control Study, Cross-sectional Study, Systematic Review, Meta-analysis, Case Report, Animal Study, In Vitro Study, Narrative Review, Clinical Observation, Diagnostic Accuracy Study, Time Series Analysis, Modeling Study, Economic Evaluation, Qualitative Study, Guideline/Consensus, Study Protocol]
   - If none match, use "Other".

2. study_timing
   - Options: [Retrospective, Prospective, Cross-sectional, Ambispective, Simulation/Model-based, Longitudinal]
   - If not applicable, use "Not Applicable".

3. focused_disease_system
   - Options: [Cardiovascular, Respiratory, Nervous, Digestive, Endocrine, Immune, Musculoskeletal, Urinary, Reproductive, Integumentary, Oncology, Infectious Disease, General Health/System, Other]

4. focused_disease
   - Specific disease name with ICD-10 if possible.
   - If general health/policy, use "Not Applicable".

5. research_team_country
   - Country name.

JSON æ ¼å¼ç¤ºä¾‹:
{{
    "research_design": "Cohort Study",
    "study_timing": "Prospective",
    "focused_disease_system": "Cardiovascular",
    "focused_disease": "Hypertension (I10)",
    "research_team_country": "USA"
}}
"""

# -----------------------------------------------------------------------------
# è¾…åŠ©å‡½æ•°
# -----------------------------------------------------------------------------
def fetch_abstract_from_pubmed(pmid):
    """æ ¹æ® PMID ä» PubMed è·å–æ‘˜è¦"""
    if not pmid or str(pmid) == 'nan':
        return None
    try:
        handle = Entrez.efetch(db="pubmed", id=str(pmid), retmode="xml")
        records = Entrez.read(handle)
        handle.close()
        
        if not records or 'PubmedArticle' not in records:
            return None
            
        article = records['PubmedArticle'][0]['MedlineCitation']['Article']
        if 'Abstract' in article and 'AbstractText' in article['Abstract']:
            abstract_parts = article['Abstract']['AbstractText']
            # AbstractText å¯èƒ½æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼ˆåˆ†æ®µæ‘˜è¦ï¼‰æˆ–å­—ç¬¦ä¸²
            if isinstance(abstract_parts, list):
                return " ".join([str(part) for part in abstract_parts])
            return str(abstract_parts)
        else:
            return "No Abstract Available" # ç¡®å®æ²¡æœ‰æ‘˜è¦
    except Exception as e:
        print(f"Error fetching PMID {pmid}: {e}")
        return None

def get_client(index):
    api_key = API_KEYS[index % len(API_KEYS)]
    return OpenAI(api_key=api_key, base_url="https://api.deepseek.com")

def analyze_abstract(args):
    """åˆ†æå•ä¸ªæ‘˜è¦"""
    index, abstract, thread_idx = args
    if not abstract or len(abstract) < 20 or abstract == "No Abstract Available":
        return index, None

    client = get_client(thread_idx)
    try:
        response = client.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "user", "content": ANALYSIS_PROMPT_TEMPLATE.format(abstract=abstract[:3000])}],
            temperature=0.1,
            response_format={'type': 'json_object'}
        )
        content = response.choices[0].message.content
        return index, json.loads(content)
    except Exception as e:
        print(f"AI Analysis failed for row {index}: {e}")
        return index, None

# -----------------------------------------------------------------------------
# ä¸»é€»è¾‘
# -----------------------------------------------------------------------------
def main():
    print(f"ğŸ“‚ Reading {FILE_PATH}...")
    try:
        df = pd.read_excel(FILE_PATH, engine='openpyxl')
    except Exception as e:
        print(f"Fatal Error: {e}")
        return

    # 1. æ‰¾å‡ºéœ€è¦é‡æ–°æŠ“å–çš„è¡Œ
    mask = (df['Abstract'].isnull()) | (df['Abstract'] == '') | (df['Abstract'] == 'Error') | (df['Abstract'].str.len() < 50)
    target_indices = df[mask].index.tolist()
    
    print(f"ğŸ” Found {len(target_indices)} rows with missing abstracts.")
    if len(target_indices) == 0:
        print("All abstracts look good.")
        return

    # 2. æ‰¹é‡æŠ“å–æ‘˜è¦ (ä¸²è¡Œæˆ–å°å¹¶å‘ï¼Œé¿å… PubMed å°ç¦)
    print("ğŸŒ Fetching abstracts from PubMed...")
    fetched_count = 0
    rows_to_analyze = [] # (index, abstract)

    for i, idx in enumerate(target_indices):
        pmid = df.loc[idx, 'PMID']
        print(f"[{i+1}/{len(target_indices)}] Fetching PMID: {pmid}...")
        
        abstract = fetch_abstract_from_pubmed(pmid)
        if abstract:
            df.at[idx, 'Abstract'] = abstract
            if abstract != "No Abstract Available":
                fetched_count += 1
                rows_to_analyze.append((idx, abstract))
                print(f"  âœ… Got abstract ({len(abstract)} chars)")
                print(f"  ğŸ“œ Preview: {abstract[:200]}...") # æ‰“å°é¢„è§ˆ
            else:
                print("  âš ï¸ No abstract available on PubMed")
        else:
            print("  âŒ Fetch failed")
        
        time.sleep(0.5) # ç¤¼è²Œå»¶æ—¶

    print(f"ğŸ“Š Fetched {fetched_count} new abstracts.")

    if not rows_to_analyze:
        print("No new abstracts to analyze.")
        # å³ä½¿æ²¡æœ‰æ–°åˆ†æï¼Œä¹Ÿè¦ä¿å­˜æŠ“å–ç»“æœï¼ˆæ¯”å¦‚ No Abstract Availableï¼‰
        df.to_excel(FILE_PATH, index=False)
        return

    # 3. å¯¹æ–°æŠ“å–çš„æ‘˜è¦è¿›è¡Œ AI åˆ†æ
    print(f"ğŸ§  Analyzing {len(rows_to_analyze)} new abstracts with AI...")
    
    tasks = []
    for i, (idx, abstract) in enumerate(rows_to_analyze):
        tasks.append((idx, abstract, i))

    analyzed_count = 0
    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:
        future_to_idx = {executor.submit(analyze_abstract, task): task[0] for task in tasks}
        
        for future in concurrent.futures.as_completed(future_to_idx):
            idx, result = future.result()
            if result:
                df.at[idx, 'Research Design'] = result.get('research_design', 'Unknown')
                df.at[idx, 'Study Timing'] = result.get('study_timing', 'Unknown')
                df.at[idx, 'Focused Disease System'] = result.get('focused_disease_system', 'Unknown')
                df.at[idx, 'Focused Disease'] = result.get('focused_disease', 'Unknown')
                df.at[idx, 'Research Team Country'] = result.get('research_team_country', 'Unknown')
                analyzed_count += 1
                print(f"  âœ… Analyzed row {idx}")

    # 4. ä¿å­˜
    backup_path = FILE_PATH.replace(".xlsx", "_backup_refetch.xlsx")
    df.to_excel(backup_path, index=False)
    df.to_excel(FILE_PATH, index=False)
    print(f"ğŸš€ Updated file saved! ({analyzed_count} rows re-analyzed)")

if __name__ == "__main__":
    main()
